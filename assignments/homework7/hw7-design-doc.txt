CS122 Assignment 7 - Write-Ahead Logging - Design Document
==========================================================

A:  Logistics
-------------

A1.  List your team name and the people who worked on this assignment.

     sqLIT

     Advith Chelikani
     Joon Lee
     Charlie Tong

A2.  Specify the repository URL, tag name and commit-hash of the Git version
     you are submitting for your assignment.  (You can list the commit hashes
     of your repository tags with this command:  git show-ref --tags)

     Repository URL:  <url>
     Tag name:        <tag>
     Commit hash:     <hash>

A3.  Specify any late tokens you are applying to this assignment, or
     "none" if no late tokens.

     Two

A4.  Briefly describe what parts of the assignment each teammate focused on.

    Advith: Enable transaction processing, Add Logging to Heap Tuple Files,
    Enforce the Write-ahead logging rule
    Joon: Implement database recovery and test write-ahead logging
    Charlie: Implement forceWAL and transaction rollback

B:  Write-Ahead Logging
-----------------------

B1.  One of your tasks this week was to implement the TransactionManager's
     forceWAL(LogSequenceNumber) method.  This method must perform its
     operation atomically and durably, so that if a crash occurs during this
     method, the WAL will always be a reliable record of database operations.
     How did you ensure that your implementation satisfies these constraints?
     Justify your approach.  (You can assume that the underlying OS provides
     an atomic file-sync operation, and that writing a single sector will
     also be atomic with the obvious caveat that the written sector may still
     be buffered until a sync occurs.)

     We wrote our method forceWAL to be atomic in the sense that there are no
     failure points where the data can be corrupted. First, we update the
     WAL on disk, writing out the contents of the log up to where we are
     syncing to. If the method fails at any point during this, then the
     log will contain additional entries on disk. However, this is fine,
     since the log will not acknowledge these extra entries (they may
     as well be garbage). Only once the transaction state is updated with
     the new NextLSN will these log records be "active."

     The transaction state is updated at the very end, once the WAL has
     been written to completely. This guarantees that the updated state
     is valid and completely on disk already. This operation is atomic
     since the transaction state is only one block on disk, and can be
     written in one write by the OS (preventing write-tearing).

B2:  Another task was to implement the beforeWriteDirtyPages() method on the
     TransactionManager.  Your implementation must ensure that the write-ahead
     logging rule is always followed.  What steps do you take to ensure this
     will always happen?  Describe your method's approach.

     We keep track of the maximum LSN of the pages we encounter that are not
     write ahead log files or transaction state files. Once we have found the
     maximum of pages with the above constraints, we force the WAL to be written
     that LSN.Finding the maximum LSN of all the pages ensures that the
     write-ahead logging rule is always followed.

B3:  In your current implementation, some pages may not have corresponding
     LSNs associated with them, because they are not logged in the write-ahead
     log.  Enumerate all file types that will have pages not logged in the
     WAL.

     Out of DBFileType, the following do not have pages logged in the WAL:
      - BTREE_TUPLE_FILE       (logging not implemented for btree files)
      - TXNSTATE_FILE          (one page only, actions are atomic)
      - WRITE_AHEAD_LOG_FILE   (this is the log itself...)

C:  The txnstate.dat File
-------------------------

C1.  The txnstate.dat file records the next transaction ID that the database
     should use when it is restarted.  Why is it important for this to be
     stored and used by the database when it is restarted?

     The next transaction ID is important as it ensures that each transaction
     has a unique ID. If multiple transactions were to share the same transaction
     ID, processes such as rollbacks or redos/undos would not function correctly.

C2:  The txnstate.dat file records a "firstLSN" value, which is where recovery
     processing starts from.  What guarantees are made about this firstLSN
     value?  Given these guarantees, will redo processing need any records
     before the firstLSN value?  Will undo processing need any records before
     the firstLSN value?  Justify your answers.

     The firstLSN value guarantees that all data files reflect all changes that
     are recorded in the write-ahead log before that LSN. Also, it guarantees
     that there are no incomplete transactions at the firstLSN point in the log.

     This means that redo processing can ignore all LSN's before this point, as
     these LSN's are already reflected in all files. Also, undo processing does
     not need any records before the firstLSN values since no transactions
     at the firstLSN point in the log are incomplete.

C3:  Currently, the "firstLSN" value is only moved forward when recovery
     processing is completed.  Can you describe a strategy for moving forward
     firstLSN during normal operation?  What constraints must be enforced to
     ensure the database continues working properly?  Explain your answers.

     A strategy for moving forward firstLSN is to

     1) Compute where the firstLSN should be according to the
     WAL's and the dirty pages currently in the buffer.
     2) Record WAL's to disk and sync
     3) Record dirty pages to disk and sync
     4) Update firstLSN

     The constraint that must be enforced is that there are no update
     operations during step (1). If there are update operations afterwards,
     this may possibly allow firstLSN to move up even more, but the
     firstLSN computed at step (1) is a safe, correct choice. If we did not
     precompute firstLSN at step (1), then an update operation during step (3)
     or step (4) might cause inconsistencies in the disk, as the dirty pages
     recorded on to disk may be more updated than the WAL's that were already
     updated, or transactions might complete in between (3) and (4), changing
     the value of firstLSN.

C4:  The txnstate.dat file's "firstLSN" value is somewhat similar to a
     checkpoint / fuzzy-checkpoint, but it is not quite the same.  Describe
     the differences between what NanoDB provides, and how checkpoints
     generally work, focusing on what constraints must be enforced during the
     checkpointing operation, vs. the constraints that NanoDB must enforce
     with firstLSN.

     As described above, NanoDB's "firstLSN" guarantees that all data files
     reflect all changes that are recorded in the write-ahead log before that
     LSN, and that there are no incomplete transactions at that point in the log.
     A "checkpoint" also guarantees that the disk reflects all changes recorded up
     to that checkpoint record, but it does not guarantee that all transactions
     at the checkpoint is completed. Hence, undo processing must check earlier
     than the checkpoint record, unlike with "firstLSN".

     In terms of constraints, the checkpoint procedure requires that no update
     operations are allowed during the procedure, while the fuzzy checkpoint procedure
     requires that no update operations are allowed while WAL's are being recorded
     onto the disk, and no update operations on already dirty pages are allowed
     afterwards. On the other hand, my strategy in C3 has the least constraints,
     since updates are allowed after step (1), which would not take as long as
     the disk IO operations in steps (2) and (3).


D:  Testing
-----------

D1:  Did you run into any fun, surprising or crazy bugs while you were
     debugging your transaction-processing code?  (It's OK if your answer
     is "no," although Donnie will be dubious...)

     We had an off-by-one error when forcing the WAL to disk, because for some
     reason Charlie thought log pages started on 1 and not 0.

E:  Extra Credit [OPTIONAL]
---------------------------

If you implemented any extra-credit tasks for this assignment, describe
them here.  The description should be like this, with stuff in "<>" replaced.
(The value i starts at 1 and increments...)

E<i>:  <one-line description>

     <brief summary of what you did, including the specific classes that
     we should look at for your implementation>

     <brief summary of test-cases that demonstrate/exercise your extra work>

F:  Feedback [OPTIONAL]
-----------------------

WE NEED YOUR FEEDBACK!  Thoughtful and constructive input will help us to
improve future versions of the course.  These questions are OPTIONAL, and
they obviously won't affect your grade in any way (including if you hate
everything about the assignment and databases in general, or Donnie and/or
the TAs in particular).  Feel free to answer as many or as few of them as
you wish.

NOTE:  If you wish to give anonymous feedback, a similar survey will be
       made available on the Moodle.

F1.  How many hours total did your team spend on this assignment?
     (That is, the sum of each teammate's time spent on the assignment.)

F2.  What parts of the assignment were most time-consuming?  Why?

F3.  Did you find any parts of the assignment particularly instructive?
     Correspondingly, did any parts feel like unnecessary busy-work?

F4.  Did you particularly enjoy any parts of the assignment?  Were there
     any parts that you particularly disliked?

F5.  Do you have any suggestions for how future versions of the
     assignment can be improved?
