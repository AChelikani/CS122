CS122 Assignment 4 - Join Optimization - Design Document
========================================================

A:  Logistics
-------------

A1.  List your team name and the people who worked on this assignment.

     sqLIT

     Advith Chelikani
     Joon Lee
     Charlie Tong

A2.  Specify the repository URL, tag name and commit-hash of the Git version
     you are submitting for your assignment.  (You can list the commit hashes
     of your repository tags with this command:  git show-ref --tags)

     Repository URL:  https://github.com/AChelikani/CS122
     Tag name:        hw4sub
     Commit hash:     998d7cb721047071c0d2ce23dc42ebb1f7c2e2df

A3.  Specify any late tokens you are applying to this assignment, or
     "none" if no late tokens.

     None

A4.  Briefly describe what parts of the assignment each teammate focused on.

    Advith: collectDetails
    Joon: makeLeafPlan
    Charlie: generateOptimalJoin and makePlan

B:  Generating Optimal Joins
----------------------------

B1.  Briefly describe how you generate an "optimal" access to a base table.

     We simply create a FileScanNode for that base table, and then
     apply all possible conjuncts to that node so that no additional
     tuples are passed to higher levels of the final plan.

B2.  Briefly describe how you decide when it is acceptable to push
     conjuncts down through an outer join.

     It is acceptable to push conjuncts down through an outer join when
     the "outer" side of the join is not opposite the child that the
     conjunct applies to. This means that it's not acceptable to push
     conjuncts down to a full outer join.

B3.  The planner in this assignment is still somewhat limited; for example,
     we can't push conjuncts down into subqueries.  Using the stores schema,
     write an example SQL query that includes a subquery, where it would be
     beneficial to push a conjunct down into the subquery.  (Your planner
     obviously doesn't need to perform this optimization.)

     SELECT store_id
     FROM (
        SELECT *
        FROM stores
        WHERE property_costs > 10000
     ) AS expensive_stores
     WHERE property_costs < 200000

B4.  Enumerate the situations where you call prepare() on plans being
     generated.  Since this operation is somewhat expensive, do you
     see any ways to reduce the number of times you call prepare() in
     your implementation?

     For each leaf node, prepare() is called at least once. If a predicate
     is added or the leaf has an alias, prepare() is called again afterwards.
     For the intermediate steps in the dynamic programming algorithm,
     prepare() is called once to compute the CPU cost. Finally, prepare()
     is called at the end of makePlan(). One way to reduce the number of times
     we call prepare() may be to call prepare() only once if a leaf node has
     an alias but no predicate. However, this may make the code very
     complicated.

B5.  In what situations can you end up with unused conjuncts after
     planning joins.  Illustrate by giving an example SQL statement
     that would have unused conjuncts after join planning, again using
     the stores schema.  Then, describe a strategy for where/how these
     left-over conjuncts should be applied in the plan.

     There can be unused conjuncts that involve grouping/aggregate functions,
     such as in the HAVING clause. For example, take the query:

     SELECT state_name, COUNT(*) AS num_cities
     FROM states JOIN cities ON states.state_id = cities.state_id
     GROUP BY state_name
     HAVING COUNT(*) > 5;

     The conjunct on COUNT(*) > 5 will be applied after the join, in a
     HashedGroupAggregate node that groups and aggregates the results. This
     can be implemented by simply taking leftover aggregate conjuncts after
     the FROM clause has been evaluated in generateOptimalJoin, and applying
     them all on top of the returned Plan.


C:  Costing SQL Queries
-----------------------

After you have loaded the stores-28K.sql data and have analyzed all of
the tables in that schema, run the following explain operations and paste
the output from your planner (excluding debug output!).

If there is anything unusual or non-obvious about your output, feel free
to write explanatory notes after your output.

C1.  EXPLAIN SELECT * FROM cities WHERE population > 5000000;

        Explain Plan:
            FileScan[table:  CITIES, pred:  CITIES.POPULATION > 5000000] cost=[tuples=99.3, tupSize=23.8, cpuCost=254.0, blockIOs=1]

        Estimated 99.262199 tuples with average size 23.787401
        Estimated number of block IOs:  1

C2.  EXPLAIN SELECT store_id FROM stores, cities
     WHERE stores.city_id = cities.city_id AND
           cities.population > 1000000;

        Explain Plan:
            Project[values:  [STORES.STORE_ID]] cost=[tuples=1776.2, tupSize=36.8, cpuCost=453194.8, blockIOs=5]
                NestedLoop[pred:  STORES.CITY_ID == CITIES.CITY_ID] cost=[tuples=1776.2, tupSize=36.8, cpuCost=451418.5, blockIOs=5]
                    FileScan[table:  CITIES, pred:  CITIES.POPULATION > 1000000] cost=[tuples=225.6, tupSize=23.8, cpuCost=254.0, blockIOs=1]
                    FileScan[table:  STORES] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4]

        Estimated 1776.238159 tuples with average size 36.787399
        Estimated number of block IOs:  5

C3.  EXPLAIN SELECT store_id FROM stores JOIN
                    (SELECT city_id FROM cities
                     WHERE population > 1000000) AS big_cities
                    ON stores.city_id = big_cities.city_id;

        Explain Plan:
            Project[values:  [STORES.STORE_ID]] cost=[tuples=1776.2, tupSize=36.8, cpuCost=453420.3, blockIOs=5]
                NestedLoop[pred:  STORES.CITY_ID == BIG_CITIES.CITY_ID] cost=[tuples=1776.2, tupSize=36.8, cpuCost=451644.1, blockIOs=5]
                    Rename[resultTableName=BIG_CITIES] cost=[tuples=225.6, tupSize=23.8, cpuCost=479.6, blockIOs=1]
                        Project[values:  [CITIES.CITY_ID]] cost=[tuples=225.6, tupSize=23.8, cpuCost=479.6, blockIOs=1]
                            FileScan[table:  CITIES, pred:  CITIES.POPULATION > 1000000] cost=[tuples=225.6, tupSize=23.8, cpuCost=254.0, blockIOs=1]
                    FileScan[table:  STORES] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4]

C4.  EXPLAIN SELECT store_id, property_costs
     FROM stores, cities, states
     WHERE stores.city_id = cities.city_id AND
           cities.state_id = states.state_id AND
           state_name = 'Oregon' AND property_costs > 500000;

        Explain Plan:
            Project[values:  [STORES.STORE_ID, STORES.PROPERTY_COSTS]] cost=[tuples=22.7, tupSize=52.5, cpuCost=11873.2, blockIOs=6]
                NestedLoop[pred:  STORES.CITY_ID == CITIES.CITY_ID] cost=[tuples=22.7, tupSize=52.5, cpuCost=11850.5, blockIOs=6]
                    NestedLoop[pred:  CITIES.STATE_ID == STATES.STATE_ID] cost=[tuples=5.8, tupSize=39.5, cpuCost=305.0, blockIOs=2]
                        FileScan[table:  STATES, pred:  STATES.STATE_NAME == 'Oregon'] cost=[tuples=1.0, tupSize=15.7, cpuCost=51.0, blockIOs=1]
                        FileScan[table:  CITIES] cost=[tuples=254.0, tupSize=23.8, cpuCost=254.0, blockIOs=1]
                    FileScan[table:  STORES, pred:  STORES.PROPERTY_COSTS > 500000] cost=[tuples=999.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4]

        Estimated 22.704525 tuples with average size 52.454067
        Estimated number of block IOs:  6

E:  Extra Credit [OPTIONAL]
---------------------------

If you implemented any extra-credit tasks for this assignment, describe
them here.  The description should be like this, with stuff in "<>" replaced.
(The value i starts at 1 and increments...)

E<i>:  <one-line description>

     <brief summary of what you did, including the specific classes that
     we should look at for your implementation>

     <brief summary of test-cases that demonstrate/exercise your extra work>

F:  Feedback [OPTIONAL]
-----------------------

WE NEED YOUR FEEDBACK!  Thoughtful and constructive input will help us to
improve future versions of the course.  These questions are OPTIONAL, and
they obviously won't affect your grade in any way (including if you hate
everything about the assignment and databases in general, or Donnie and/or
the TAs in particular).  Feel free to answer as many or as few of them as
you wish.

NOTE:  If you wish to give anonymous feedback, a similar survey will be
       made available on the Moodle.

F1.  How many hours total did your team spend on this assignment?
     (That is, the sum of each teammate's time spent on the assignment.)

F2.  What parts of the assignment were most time-consuming?  Why?

F3.  Did you find any parts of the assignment particularly instructive?
     Correspondingly, did any parts feel like unnecessary busy-work?

F4.  Did you particularly enjoy any parts of the assignment?  Were there
     any parts that you particularly disliked?

F5.  Do you have any suggestions for how future versions of the
     assignment can be improved?
